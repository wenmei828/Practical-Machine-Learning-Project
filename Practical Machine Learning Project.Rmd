---
title: "Practical Machine Learning Project"
author: "XL"
date: "Thursday, August 07, 2014"
output: html_document
---

The data for this project come from this source: <http://groupware.les.inf.puc-rio.br/har>.

## Task

The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases.

## Data Preprocessing
    
    **-Load data.**  
    **-Verify that the column names (excluding classe and problem_id) are identical in the training and test set.**    
    **-Remove first six columns, near zero covariates and those with more than 95% of NA or "" values since these variables will not provide much power for prediction.**   
    **-Transform the "classe" variable in a factor var**    
    **-Split the training set into training and cross validation to have a measure of out-of-sample error.**      
    

```{r}
library(caret)
set.seed(123)
training = read.csv("pml-training.csv", header = TRUE)
testing = read.csv("pml-testing.csv", header = TRUE)
colnames_train <- colnames(training)
colnames_test <- colnames(testing)
all.equal(colnames_train[1:length(colnames_train)-1], colnames_test[1:length(colnames_train)-1])
training <- training[, 7:dim(training)[2]]
treshold <- dim(training)[1] * 0.95
goodColumns <- !apply(training, 2, function(x) sum(is.na(x)) > treshold  || sum(x=="") > treshold)
training <- training[, goodColumns]
badColumns <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, badColumns$nzv==FALSE]
training$classe = factor(training$classe)
inTrain <- createDataPartition(training$classe, p = 0.6)[[1]]
crossv <- training[-inTrain,]
training <- training[ inTrain,]
inTrain <- createDataPartition(crossv$classe, p = 0.75)[[1]]
crossv_test <- crossv[ -inTrain,]
crossv <- crossv[inTrain,]
```

## Building the Model
We can now create a model based on the pre-processed data set.       
Initially I was planning a model with 3 predictors: a random forest, a boosting predictor, and a linear classifier.

```{r}
#Train 3 different models
set.seed(828)
mod1 <- train(classe ~ ., data=training, method="rf")
mod2 <- train(classe ~ ., data=training, method="gbm",verbose = FALSE)
mod3 <- train(classe ~ ., data=training, method="lda")
pred1 <- predict(mod1, crossv)
pred2 <- predict(mod2, crossv)
pred3 <- predict(mod3, crossv)
#show confusion matrices
confusionMatrix(crossv$classe, pred1)
confusionMatrix(crossv$classe, pred2)
confusionMatrix(crossv$classe, pred3)
#out-of-sample error
pred1_test <- predict(mod1, crossv_test)
pred2_test <- predict(mod2, crossv_test)
pred3_test <- predict(mod3, crossv_test)
confusionMatrix(crossv_test$classe, pred1_test)
confusionMatrix(crossv_test$classe, pred2_test)
confusionMatrix(crossv_test$classe, pred3_test)
```

##Final model and prediction
Comparing model accuracy of the two models generated, random forest model has overall better accuracy. So, I'll use this model for prediction.

```{r}
# final model
mod1$finalModel
# prediction
prediction <- as.character(predict(mod1, testing))
# write prediction files
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_", i, ".txt")
    write.table(x[i], file = filename, quote = FALSE, row.names = FALSE, col.names = FALSE)
  }
}
pml_write_files(prediction)
```

